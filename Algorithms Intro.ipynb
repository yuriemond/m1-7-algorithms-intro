{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Algorithms Intro.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPnnTWlvAJmTRJIVodZ0Oxq"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"2wP4Wgr0c9Tz","colab_type":"text"},"source":["# Algorithms!\n","\n","An algorithmare is any method used to solve some computational problem. Some examples:\n","\n","- How to take a list of numbers and re-arrange them in sorted order\n","\n","- How to find the shortest path between two points on a map\n","\n","- Finding the optimal order in which to complete a list of related tasks to minimize the effort/time taken\n","\n","**Fun Fact:** The name *Algorithm*, like *Algebra* and the Arabic numeral system we still use today all come from the same genius of the islamic golden age, [Muhammad ibn Musa al-Khwarizmi](https://en.wikipedia.org/wiki/Muhammad_ibn_Musa_al-Khwarizmi)\n","\n","\n","Algorithms are a key component of all areas of computer science (both in theory and in practice), and in many fields of science (economics, biology, mechanical and structural engineering, etc.). \n","\n","Of course, machine learning is also completely dependent on designing relevant algorithms.\n","\n","In short, they're important!\n","\n","In the algorithm module of this course we'll learn the following:\n","\n","* A **framework and vocabulary** to design and analyze algorithms\n","\n","* A few algorithm **design paradigms**:\n","\n","  * Divide and conquer algorithms\n","  * Greedy Algorithms\n","  * Numeric Algorithms\n","    * Approximation algorithms\n","    * Randomized algorithms\n","  * Optimization algorithms\n","    * Dynamic Programming/backtracking\n","    * Branch-and-bound/Prune-and-search\n","  * Parallel Algorithms\n","\n","* Algorithm **data structures**\n","  * Graph Algorithms\n","  * Trees, hashing, etc.\n","\n","In short we have a lot of work to do! So let's get started!\n","\n","# Algorithm speed\n","\n","The best way to introduce the notion of speed is with an old joke:\n","\n","> Shlemiel gets a job as a street painter, painting the dotted lines down the middle of the road. On the first day he takes a can of paint out to the road and finishes 300 yards of the road. \"That's pretty good!\" says his boss, \"you're a fast worker!\" and pays him a kopeck.\n","\n","> The next day Shlemiel only gets 150 yards done. \"Well, that's not nearly as good as yesterday, but you're still a fast worker. 150 yards is respectable,\" and pays him a kopeck.\n","\n","> The next day Shlemiel paints 30 yards of the road. \"Only 30!\" shouts his boss. \"That's unacceptable! On the first day you did ten times that much work! What's going on?\" \"I can't help it,\" says Shlemiel. \"Every day I get farther and farther away from the paint can!\" \n","\n","Algorithms generally care about how **efficient** they are at solving a particular problem -- they want to minimize the number of \"steps\" you have to take to complete a task.\n","\n","# Algorithm Problems\n","\n","Algorithms generally are studied in the context of a particular problem -- finding a method to find a solution (algorithm output) for a certain query (the input).\n","\n","For instance we define the **sorting problem** as follows:\n","\n","$$Input:\\ A\\ sequence\\ of\\ numbers\\ [a_1, a_2, ..., a_n]$$\n","\n","$$Output:\\ A\\ reordering\\ (permutation)\\ [a_1^{'}, a_2^{'}, ..., a_n^{'}]\\ such\\ that\\ a_1^{'} \\leq a_2^{'} \\leq ... \\leq a_n^{'}$$\n","\n","For instance, $SORT([1, 3, 2, 5, 4]) \\rightarrow [1, 2, 3, 4, 5]$.\n","\n","**Note the relationship between algorithms and functions!** Algorithms are types of functions in mathematics and the mathematical tools of functions are useful to study algorithms in general.\n","\n","Also **note** that sorting is only related to the type supporting a $\\ge$ operation! Sorting is defined on *any ordered Set of elements* as we saw in lecture 2.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Vl0WAH8rnT7J","colab_type":"text"},"source":["# The Sorting Problem\n","\n","One of the simplest algorithm to solve the sorting problem is called **selection sort**. To define it we'll use [pseudocode](https://en.wikipedia.org/wiki/Pseudocode) then write it in python. Here's the pseudocode for selection sort:\n","\n","1. Find the smallest element. Swap it with the first element\n","\n","2. Find the 2nd-smallest element. Swap it with the 2nd\n","\n","3. Repeat finding the next-smallest, and swapping it into the position you're at until the array is sorted.\n","\n","One thing we we're missing to build the algorithm for **selection sort** right away is **linear search**, a procedure that takes a list and finds the index where the minimum element in the list is.\n","\n","### Linear Search\n","\n","**Input:** A sequence of numbers $A=[a_1, a_2, ..., a_n]$\n","\n","**Output:** An integer $i$ such that $A[i] = min(A)$"]},{"cell_type":"code","metadata":{"id":"hlSQNyBMuFaa","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595459181793,"user_tz":240,"elapsed":841,"user":{"displayName":"Matthieu Ranger","photoUrl":"","userId":"05160963434497794589"}},"outputId":"e91fff15-3498-4504-e096-ea709bcfd09e"},"source":["# Exercise: Students should try for 5-10 minutes to write linear search themselves\n","# If a student has a working solution, ask him to send it and critique it\n","# If no one does, take a student who feels close and get his code there\n","# If students finish in advance, tell the teacher privately \n","#    (not to stress slower students)\n","\n","# Solution:\n","def linear_search(arr):\n","  \"\"\"\n","  Find the index of the minimum element\n","  AKA argsort\n","  \"\"\"\n","  # initialize current best to +infinity\n","  # So any element beats it\n","  current_min = float('inf')\n","  current_min_idx = 0\n","  for i in range(len(arr)):\n","    if arr[i] < current_min:\n","      current_min = arr[i]\n","      current_min_idx = i\n","  return current_min_idx\n","\n","linear_search([1,4,3,-99,5])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"markdown","metadata":{"id":"S8ootYXkuFrS","colab_type":"text"},"source":["Now let's build **selection sort** in python! We should build a function `selection_sort(arr)` which takes a `list` or numpy array object and sort it in place (returning nothing)."]},{"cell_type":"code","metadata":{"id":"k-4dCpP9b5Nf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595459168292,"user_tz":240,"elapsed":829,"user":{"displayName":"Matthieu Ranger","photoUrl":"","userId":"05160963434497794589"}},"outputId":"dbffff9c-1910-42f4-c5ad-3df07bb1b574"},"source":["# Exercise: Students should try for 15-20 minutes to write selection sort themselves\n","# Do the same as in linear search (upgrade/critique a student's answer)\n","\n","\n","# Solution:\n","def selection_sort(arr):\n","  \"\"\"Selection sort\"\"\"\n","  n_sorted = 0\n","  while n_sorted < len(arr):\n","    # Get the index of the min of remaining elements\n","    # Since argsort returns based on array, we correct result\n","    # with `+ n_sorted`\n","    min_idx = linear_search(arr[n_sorted:]) + n_sorted\n","    # Swap minimum element with leftmost remaining element\n","    to_swap = arr[n_sorted]\n","    arr[n_sorted] = arr[min_idx]\n","    arr[min_idx] = to_swap\n","    # Increment and restart\n","    n_sorted += 1\n","\n","\n","arr = [111,4,3,22,5,44.4,66.6,777]\n","selection_sort(arr)\n","arr"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[3, 4, 5, 22, 44.4, 66.6, 111, 777]"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"markdown","metadata":{"id":"aCDglvBffk3T","colab_type":"text"},"source":["# Big-O\n","\n","The computer scientists analyze algorithms is with the **Big-O** notation. \n","\n","Big-O cares about how the number of steps we have to take **grow in relation to input size**. \n","\n","For instance, for `linear_search`, we make a full pass through all the elements in the input array. We would say this is $O(n)$ because as the size of the input array $n$ grows, we have to take $n$ steps through the array to terminate the `linear_search` algorithm.\n","\n","### Notes on Big-O notation:\n","\n","Big-O is a theoretical way to think about algorithms. Big-O doesn't care about what programming language you use, what computer you run your code on, or even how much time it takes to run the algorithm in real life.\n","\n","Big-O **only cares about how the number of steps** taken grow with respect to the size of the input.\n","\n","### Laws of Big-O\n","\n","1. **Big-O only cares about the worst case**\n","\n","The Big-O of and algorithm is always going to be worst case the algorithm can run. \n","\n","For example, imagine we made a variation of `linear_search` where instead of searching for the minimum element, we searched for a specific number (and returned false if we didn't find it).\n","\n","The Big-O of that would be $O(n)$, since in the worst case we do one full pass through all the elements in the array.\n","\n","2. **Big-O doesn't care about constant factors**. \n","\n","In an equation like\n","\n","$$ y = 55 + 6x^2$$\n","\n","the number $55$ is a *constant* -- it's the same whatever the input and output is. Big-O doesn't care about that, so we can say\n","\n","$$O(10^{25} + n) = O(n)$$\n","\n","Which might seem crazy -- clearly $(10^{25} + n) > n$ for all $n$. But \n","\n","Also note that sometimes we talk about the big-O of the **memory** required by the algorithm. For instance, in `selection_sort`, we need one copy of the input array to work on, so the memory required is $O(n)$. If we needed to make a copy\n","\n","3. **Big-O doesn't care about low-order terms**\n","\n","Low order terms are constant multipliers of the input. So $O(6n) = O(n) = O(10^{12}n)$. We care about multipliers that are in terms of $n$ (like $log(n)$ ) or exponents on $n$ (like $n^3$).\n","\n","4. **Algorithms that take the same number of steps for all inputs are** $O(1)$.\n","\n","They just are. That's a thing.\n","\n","### Analysis: Selection Sort\n","\n","For `selection_sort`, we do one $O(n)$ linear search for all $n$ elements in the array. This means we need:\n","\n","$$n * O(n) = O(n^2)$$\n","\n","So the number of steps selection sort has to take to terminate is **squared the number of input elements**.\n","\n","That's not very good! If you needed to sort $1,000,000,000$ elements it would take $1,000,000,000^2$ steps!\n","\n","Luckily there are some better algorithms we'll explore soon.\n","\n","### Example 2: Multiplying integers \n","\n","The algorithm for multiplying two integers might seem like an easy thing solved a few millenia ago, but in fact it's still [an area of active research](https://www.quantamagazine.org/mathematicians-discover-the-perfect-way-to-multiply-20190411/). The algorithm you learned in grade school looks like this:\n","\n","1. Take two numbers, x and y, line them up along the smallest digit\n","\n","2. For each pair of digits, starting at the least significant digit multiply them and carry the remainder\n","\n","3. Repeat with the second least significant digit, multiplying remainders\n","\n","4. Repeat with the third least significant digit, and so on\n","\n","This is another algorithm that is $O(n^2)$. For a long time people thought it was impossible to do it faster than $O(n^2)$. This was improved to $O(n^{1.58})$ in 1962 by [Karatsuba](https://en.wikipedia.org/wiki/Karatsuba_algorithm) and people have been trying to get the \"best score\" at this for decades since -- in the article I linked, it's been recently been improved to $O(n log(n))$.\n"]},{"cell_type":"code","metadata":{"id":"J9rANIiifkF1","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cu5bYkz9fkIn","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}